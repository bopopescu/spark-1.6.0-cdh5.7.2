From 01462646de8e46e93d78622520bac3834aa26520 Mon Sep 17 00:00:00 2001
From: Marcelo Vanzin <vanzin@cloudera.com>
Date: Fri, 22 Jan 2016 16:29:57 -0800
Subject: [PATCH 032/201] CLOUDERA-BUILD. Fix Spark's use of Hive's
 VariableSubtitution.

This (internal) Hive API has changed and adjustments are needed in
Spark for things to compile.
---
 .../org/apache/spark/sql/hive/HiveContext.scala    |    8 +++++---
 .../spark/sql/hive/client/ClientInterface.scala    |    3 +++
 .../spark/sql/hive/client/ClientWrapper.scala      |    2 ++
 3 files changed, 10 insertions(+), 3 deletions(-)

diff --git a/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala b/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala
index ffb629a..4cb6a82 100644
--- a/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala
+++ b/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala
@@ -20,6 +20,7 @@ package org.apache.spark.sql.hive
 import java.io.File
 import java.net.{URL, URLClassLoader}
 import java.sql.Timestamp
+import java.util.{Map => JMap}
 import java.util.concurrent.TimeUnit
 import java.util.regex.Pattern
 
@@ -30,10 +31,9 @@ import scala.language.implicitConversions
 import org.apache.hadoop.fs.{FileSystem, Path}
 import org.apache.hadoop.hive.common.StatsSetupConst
 import org.apache.hadoop.hive.common.`type`.HiveDecimal
-import org.apache.hadoop.hive.conf.HiveConf
+import org.apache.hadoop.hive.conf.{HiveConf, HiveVariableSource, VariableSubstitution}
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars
 import org.apache.hadoop.hive.ql.metadata.Table
-import org.apache.hadoop.hive.ql.parse.VariableSubstitution
 import org.apache.hadoop.hive.serde2.io.{DateWritable, TimestampWritable}
 import org.apache.hadoop.util.VersionInfo
 
@@ -195,7 +195,9 @@ class HiveContext private[hive](
     sc.conf.get("spark.sql.hive.thriftServer.singleSession", "false").toBoolean
 
   @transient
-  protected[sql] lazy val substitutor = new VariableSubstitution()
+  protected[sql] lazy val substitutor = new VariableSubstitution(new HiveVariableSource() {
+    override def getHiveVariable(): JMap[String, String] = metadataHive.hiveVariables
+  })
 
   /**
    * The copy of the hive client that is used for execution.  Currently this must always be
diff --git a/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientInterface.scala b/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientInterface.scala
index 9d9a55e..23da0d3 100644
--- a/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientInterface.scala
+++ b/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientInterface.scala
@@ -93,6 +93,9 @@ private[hive] trait ClientInterface {
   /** Returns the configuration for the given key in the current session. */
   def getConf(key: String, defaultValue: String): String
 
+  /** Returns variables used for substitution in queries. */
+  def hiveVariables: JMap[String, String]
+
   /**
    * Runs a HiveQL command using Hive, returning the results as a list of strings.  Each row will
    * result in one string.
diff --git a/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientWrapper.scala b/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientWrapper.scala
index 598ccde..fa8a79f 100644
--- a/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientWrapper.scala
+++ b/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/ClientWrapper.scala
@@ -204,6 +204,8 @@ private[hive] class ClientWrapper(
   /** Returns the configuration for the current session. */
   def conf: HiveConf = SessionState.get().getConf
 
+  override def hiveVariables: JMap[String, String] = SessionState.get().getHiveVariables()
+
   override def getConf(key: String, defaultValue: String): String = {
     conf.get(key, defaultValue)
   }
-- 
1.7.9.5

